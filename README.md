# Pretrained Language Model Weight and Paper Summary

1. **Google Bert**: https://github.com/google-research/bert https://arxiv.org/pdf/1810.04805.pdf
2. **Google alBert**: https://github.com/google-research/ALBERT https://openreview.net/pdf?id=H1eA7AEtvS
3. **brightmart RoBERTa**: https://github.com/brightmart/roberta_zh https://arxiv.org/pdf/1907.11692.pdf
4. **哈工大-RoBERTa**: https://github.com/ymcui/Chinese-BERT-wwm
5. **华为-NEZHA哪吒**: https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/NEZHA https://arxiv.org/pdf/1909.00204.pdf
6. **Goole-T5**: https://github.com/google-research/text-to-text-transfer-transformer https://arxiv.org/pdf/1910.10683.pdf
7. **stanford&Google-electra**: https://github.com/google-research/electra https://openreview.net/pdf?id=r1xMH1BtvB 

* 邱锡鹏老师-自然语言处理预训练模型综述 https://arxiv.org/pdf/2003.08271.pdf
> 持续更新......
